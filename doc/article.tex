\documentclass[a4paper]{classrep}
\usepackage{polski}
\input{packages-article}
\usepackage{multirow}

\studycycle{Informatyka, studia dzienne, II st.}
\coursesemester{II}

\coursename{Komputerowe systemy rozpoznawania}
\courseyear{2013/2014}

\courseteacher{dr hab. inż. Adam Niewiadomski, prof. PŁ}
\coursegroup{poniedziałek, 10:30}

\author{%
  \studentinfo{Mateusz Grotek}{186816} \and
  \studentinfo{Paweł Tarasiuk}{186875}
}

\title{Zadanie 1.: Ekstrakcja cech, miary podobieństwa, klasyfikacja}

\begin{document}
\maketitle
\section{Cel}
Celem niniejszego zadania jest zbadanie różnych metod ekstrakcji cech
oraz miar podobieństwa dla tekstu i zastosowanie ich w procesie klasyfikacji słabym klasyfikatorem kNN.
Omówione zostaną metody znane w literaturze oraz nasze własne pomysły,
a wszystkie te elementy znajdą swoje odzwierciedlenie w przygotowanej
przez nas implementacji, co umożliwi nam wygenerowanie i ocenę wyników
działania różnych metod.
\section{Wprowadzenie}
\subsection{Podstawowe algorytmy}
Klasyfikator kNN (k nearest neighbours, k najbliższych sąsiadów) to słaby klasyfikator, posiadający jednak istotną zaletę jaką jest prostota implementacji. Słabość klasyfikatora rozumiemy tak jak w teorii boostingu -- słabym nazywamy taki klasyfikator, który nie zawsze jest w stanie osiągnąć dowolnie wysoką dokładność klasyfikacji.
Dlatego jest on szeroko stosowany, gdyż pomimo swojej prostoty daje relatywnie dobre wyniki. Dodatkowo można go użyć w technikach typu AdaBoost,
które pozwalają z kilku słabych klasyfikatorów stworzyć jeden silny. Jego idea polega na wybraniu takiej kategorii która jest najczęstsza wśród sąsiadów wektora podlegającego klasyfikacji.
Potencjalni sąsiedzi są dostarczani do klasyfikatora na etapie jego uczenia. Aby wskazać najbliższych sąsiadów należy oczywiście użyć jakiejś miary odległości, czyli metryki.
Istnieje też odmiana klasyfikatora, którą moglibyśmy określić jako k najbardziej podobnych sąsiadów. W tej odmianie zamiast odległości w zadanej metryce używana jest funkcja podobieństwa.
Pokazuje to jak szerokie zastosowanie może mieć ten klasyfikator.

W naszym projekcie użyliśmy następujących funkcji podobieństwa:
\begin{itemize}
\item miara Jaccarda na słowach po filtracji stoplistą i stemizacji jako podobieństwo tekstów
\begin{equation}
\label{eq:jaccard}
J(A,B) = \frac{\mu(A\cap B)}{\mu(A \cup B)}
\end{equation}
\item metoda \(n\)-gramów (użyliśmy metody 3-gramów, gdyż tekst jest tekstem angielskim, przy czym użyliśmy 3-gramów w mierze podobieństwa zdań)
\begin{eqnarray}
\textrm{sim}_3(s_1,s_2) & = & \frac{1}{N-2}\sum_{i=1}^{N-2}h(i) \\
\label{eq:ngram}
\mu_{N_z}(z_1, z_2) & = & \frac{1}{N} \sum_{i=1}^{N(z_1)}\max_{j=1,\ldots,N(z_1)} \textrm{sim}_3(s_{1j}, s_{2i})
\end{eqnarray}
\item autorska metoda bazująca na słowach kluczowych i prostym współczynniku dopasowania (patrz sekcja \ref{sec:autorskiepodobienstwo})
\end{itemize}
Użyte zostały następujące metryki:
\begin{itemize}
\item metryka euklidesowa
\begin{equation}
\label{eq:euklides}
d_e(X,Y)=\sqrt{\sum_{i=1}^n(x_i-y_i)^2}
\end{equation}
\item metryka uliczna
\begin{equation}
\label{eq:uliczna}
d_1(X,Y)=\sum_{i=1}^n|x_i-y_i|
\end{equation}
\item metryka Czebyszewa
\begin{equation}
\label{eq:czebyszew}
d_\infty(X,Y)=\max_{i=1,\ldots,n}|x_i-y_i|
\end{equation}
\end{itemize}

Klasyfikacji można dokonywać bezpośrednio na podanych tekstach, jednak takie rozwiązanie charakteryzuje się wysokim kosztem obliczeniowym. Dlatego często lepiej jest
wyekstrahować ze zbiorów pewne wektory cech, które pozwolą szybko sklasyfikować dane teksty. Wybór wektorów cech zależy od postawionego zadania.
W naszym projekcie użyliśmy trzech sposobów ekstrakcji cech:
\begin{enumerate}
\item naiwny sposób bazujący na użyciu wszystkich słów (po filtracji przez stoplistę i stemizacji), ilość wymiarów wektora jest zależna od ilości wszystkich słów w zbiorze uczącym (patrz sekcja \ref{sec:naiwna})
\item bazujący na słowach kluczowych (jak powyżej, ale wybierane są tylko słowa kluczowe, co zmniejsza ilość wymiarów) (patrz sekcja \ref{sec:kluczowe})
\item autorska metoda bazująca na zbiorach rozmytych (opis poniżej) (patrz sekcja \ref{sec:autorska})
\end{enumerate}

Sama klasyfikacja została wykonana na dwóch zbiorach danych, każdy podzielony na podzbiór uczący i podzbiór testowy, przy czym sposób podziału jest wybierany w aplikacji.
Można dokonać podziału w sposób losowy (przy zadanych proporcjach), lub w ustalony sposób (60\% początkowych tekstów jako zbiór uczący, reszta to zbiór testowy).
Użyliśmy następujących zbiorów danych:
\begin{enumerate}
\item zestaw krótkich wiadomości prasowych firmy Reuters,
\item przygotowany przez nas zestaw fragmentów tekstów znanych pisarzy.
\end{enumerate}
Teksty prasowe zostały sklasyfikowane na podstawie dwóch kategorii: miejsca którego dotyczą i tematu.
Jeśli chodzi o teksty znanych pisarzy, to zostały one sklasyfikowane kategorią, którą są nazwiska pisarzy.
\subsection{Naiwna metoda ekstrakcji cech}
\label{sec:naiwna}
Do celów porównawczych zaimplementowaliśmy naiwną metodę ekstrakcji. Metoda ta działa w następujący sposób. Najpierw teksty są dzielone na słowa. Słowa te podlegają prostej stemizacji,
a następnie filtrowane są przez stop-listę. Otrzymujemy zestaw skończonych ciągów słów. Każdemu słowu z zestawu (w sensie typu, a nie egzemplarza słowa) przypisywana jest pozycja
w wektorze (w kolejności występowania słów). Następnie dla każdego tekstu budowany jest wektor w którym na kolejnych pozycjach występują ilości znalezionych słów.
\subsection{Metoda ekstrakcji cech bazująca na słowach kluczowych}
\label{sec:kluczowe}
Ta metoda działa podobnie do powyższej, jednakże zamiast użycia wszystkich słów, zostały użyte tylko słowa kluczowe. Dla notatek prasowych użyliśmy zestawu słów kluczowych znajdujących się w kolekcji. Dla autorów opracowaliśmy automatycznie własny zestaw słów kluczowych. Dzięki użyciu słów kluczowych zmniejszyła się ilość wymiarów w wektorze cech.
\subsection{Autorska metoda ekstrakcji cech}
\label{sec:autorska}
Poniżej omówimy autorskie metody ekstrakcji cech i miarę podobieństwa, których użyliśmy. 
Główną ideą naszej metody ekstrakcji są słowa kluczowe. Zbiór takich słów należy przygotować dla konkretnego zadania. Może on być wyznaczony ręcznie,
lub wygenerowany automatycznie na podstawie danych uczących. Zbiór takich słów dzielimy na podzbiory na podstawie ich znaczenia. Można oczywiście używać tylko jednego podzbioru
w którym są umieszczone wszystkie słowa kluczowe, ale zwiększenie ilości podzbiorów może poprawić klasyfikację, ze względu na zwiększenie wymiarowości przestrzeni. 
W jednym podzbiorze powinny być słowa oznaczająca podobne obiekty, na przykład nazwy geograficzne. Następnie dla każdej kategorii względem której klasyfikujemy przygotowujemy
osobny zestaw podzbiorów. Inaczej mówiąc jeżeli kategorią jest ,,kanada'' a w jednym z podzbiorów znajdują się ,,organizacje'', to tworzymy podzbiór ,,kanadyjskie organizacje''.
Widać, że jest to metoda analogiczna do tego jak ludzie kategoryzują obiekty. Wystarczy następnie zauważyć, że określenie ,,kanadyjskie organizacje'' możemy modelować
jako pewien zbiór rozmyty. Niektóre organizacje są stricte kanadyjskie, inne tylko częściowo. Na podstawie danych uczących, lub wiedzy eksperckiej jesteśmy w stanie podać
funkcję przynależności do danego zbioru.

Mając taki zestaw zbiorów możemy wyekstrahować cechy z tekstów zbioru uczącego i na tej podstawie nauczyć klasyfikator. Ekstrakcja przebiega następująco. Wstępnie każdy element wektora
cech jest liczbą, która jest sumą wartości funkcji przynależności dla każdego słowa, kluczowego z podanego zbioru rozmytego, które wystąpiło w podanym tekście.
Opisuje to wzór
\begin{equation}
V_T(n)=\sum_{s\in K(n) \cap T} \mu_{K(n)}(s)
\end{equation}
gdzie:
\begin{itemize}
\item \(T\) to tekst (jako zbiór słów) z którego ekstrahujemy cechy,
\item \(n\) to numer składowej wektora cech którą obliczamy,
\item \(K(n)\) to \(n\)-ty zbiór rozmyty słów kluczowych,
\item \(\mu_{K(n)}(s)\) to funkcja przynależności słowa \(s\) do zbioru \(K(n)\).
\end{itemize}
\noindent Następnie wektor \(V_T\) jest normalizowany do długości równej \(1\) według wzoru
\begin{equation}
V_T' = \frac{V_T}{|V_T|}
\end{equation}

Przykładowo, załóżmy, że mamy 2 teksty postaci:
\begin{description}
\item [T1]Showers continued throughout the week in the Bahia cocoa zone. Ms Smith said there is still some doubt as to how 
much old crop cocoa is still available as harvesting has practically come to an end.
\item [T2]``I'd put it off as long as they conceivably could,'' said Lawrence Cohn, analyst with Merrill Lynch, Pierce, Fenner and Smith.
\end{description}
Załóżmy także, że tekst 1 jest przyporządkowany do kategorii ,,el-salvador'', a tekst 2 do kateogrii ,,usa''.
Do dyspozycji mamy 3 słowa (frazy) kluczowe: ,,bahia'', ,,smith'', ,,merill lynch''. Załóżmy także, że mamy dwa następujące zbiory rozmyte słów (fraz) kluczowych:
\begin{eqnarray*}
\textrm{elSalvadorWords}\;\;\;= &\{& \\
  && <\textrm{bahia}; 1{,}0>, \\
  && <\textrm{smith}; 0{,}2>, \\
  && <\textrm{merill lynch}; 0{,}0> \\
  &\}& \\
\textrm{usaWords}\;\;\;= &\{& \\
  && <\textrm{bahia}; 0{,}0>, \\
  && <\textrm{smith}; 0{,}7>, \\
  && <\textrm{merill lynch}; 0{,}9> \\
  &\}&
\end{eqnarray*}
Naszym zadaniem jest utworzyć dwa wektory cech opisujących powyższe teksty. Zgodnie z powyższymi wzorami Wektory te będą wyglądać następująco:
\begin{eqnarray*}
V_{T1} &=& <1{,}2; 0{,}7> \\
V_{T2} &=& <0{,}2; 1{,}6>
\end{eqnarray*}
a po normalizacji:
\begin{eqnarray*}
V_{T1}' &\approx& <0{,}86; 0{,}50> \\
V_{T2}' &\approx& <0{,}12; 0{,}99>
\end{eqnarray*}

\subsection{Autorska funkcja podobieństwa}
\label{sec:autorskiepodobienstwo}
Natomiast jeśli chodzi o obliczanie funkcji podobieństwa, metoda ta również opiera się na słowach kluczowych. Dla słów kluczowych, które znajdują się w obu tekstach, liczony jest prosty współczynnik dopasowania (simple matching coefficient), wyznaczony
wzorem
\begin{equation}
SMC(A,B) = \frac{\mu(A \cap B)+\mu(A^C \cap B^C)}{\mu(X)}
\end{equation}
Dzięki użyciu słów kluczowych jesteśmy w stanie znaleźć przestrzeń \(X\), gdyż jest to po prostu zestaw wszystkich słów kluczowych.
Na przykład dla powyższych tekstów i zbiorów rozmytych mamy następującą wartość funkcji:
\[SMC(T1,T2) = \frac{1}{3}\]
%Tworzymy 36 zbiorów rozmytych, po jednym dla każdej kombinacji podzbioru słów kluczowych i klasy.
%Do każdego zbioru rozmytego dla określonej kategorii i określonej klasy wrzucamy wszystkie słowa kluczowe z tej kategorii i początkowo przypisujemy im \(0{,}0\) jako wartośc
%funkcji przynależności do zbioru. Następnie przeglądamy zbiór uczący i do każdego elementu elementu przypisujemy stosunek pojawiania się danego słowa kluczowego w danej klasie
%względem jego pojawiania się we wszystkich klasach. Na przykład, jeżeli słowo pojawiło się w tekstach dotyczących kanady \(x\) razy, a we wszystkich tekstach pojawiło się \(y\) razy,
%to stosunek wynosi \(x/y\). Stosunek ten mówi jak dobrze słowo pasuje do podanej klasy. Na wejście kNN podajemy wektory uczące zawierające 36 wartości. Wektory te obliczamy dla
%tekstów uczących jako sumę wartości funkcji przynależności wystąpień każdego słowa podzieloną przez długość danego wektora.
%
%Algorytm ten jest rozszerzoną wersją prostszego algorytmu, który po prostu zlicza wystąpienia słów kluczowych w tekście. Dzięki uwzględnieniu rozmytości nie ma problemu ze słowami,
%które dobrze opisują więcej niż jedną klasę. Na przykład angielskie nazwiska pasują równie dobrze do wielkiej brytanii, jak i usa, więc będą miały mniejszą wagę,
%niż nazwiska japońskie przy rozpoznawaniu kraju.
%
%Dodatkową regułą, którą chcielibyśmy zastosować jest domyślne przypisanie do klasy usa w wypadku, gdy wartości dla innych klas nie przekraczają pewnej wartości. Reguła ta będzie
%szczególnie użyteczna w wypadku rozróżnienia między usa i uk.
\section{Opis implementacji}
%{\color{blue}
%Należy tu zamieścić krótki i zwięzły opis zaprojektowanych klas oraz powiązań
%między nimi. Powinien się tu również znaleźć diagram UML  (diagram klas)
%prezentujący najistotniejsze elementy stworzonej aplikacji. Należy także
%podać, w jakim języku programowania została stworzona aplikacja. }
Implementacja programu została wykonana w języku Java. Poniżej prezentujemy orientacyjny wycinek diagramu klas naszego programu.
\obraz{uml}{uml}{Wycinek uproszczonego diagramu klas aplikacji}
Przygotowane rozwiązanie zawiera w sobie także interfejs graficzny wykonany
przy wykorzystaniu biblioteki Swing. Wybór ten został podyktowany tym, że
biblioteka ta jest domyślnie obecna w środowisku uruchomieniowym Javy,
dzięki czemu nasz projekt nie ma żadnych dodatkowych zewnętrznych zależności.
Interfejs pozwala wybrać przetwarzany zestaw danych, dopasować parametry
wskazywania zbioru uczącego i testowego oraz daje dostęp do wszystkich
dostępnych w projekcie metod i parametrów ekstrakcji cech, porównywania próbek
i klasyfikacji. Po ustaleniu wszystkich właściwości zadanego problemu
program wyświetla uogólnioną informację o tym, jaka część próbek została sklasyfikowana
poprawnie oraz pozwala zapisać szczegółowe wyniki w plikach csv. Dostępne są
trzy tryby generowania szczegółowych wyników:
\begin{itemize}
\item Raport z poszczególnych próbek ze zbioru testowego (do jakiej kategorii powinny należeć, a do jakiej zostały zaklasyfikowane)
\item Statystyki TPR (jaka część próbek które powinny do niej należeć faktycznie do niej trafiła) i PPV (jaka część próbek zaklasyfikowanych do danej kategorii faktycznie do niej należy) opisujące każdą z kategorii
\item Macierz, w której dla każdej pary właściwa kategoria/kategoria wskazana przez klasyfikator przechowywane są liczby przypadków w których tak się stało
\end{itemize}

\section{Materiały i metody}
Eksperymenty przeprowadzane były dla trzech problemów klasyfikacji:
\begin{enumerate}
\item \textbf{Kraje} -- klasyfikacja próbek tekstowych ze zbioru
\emph{Reuters-21578 Text Categorization Collection Data Set}, gdzie jako etykiety
wybrane zostały kraje, których dotyczy dana próbka. Wybrane zostały wyłącznie
te próbki, które dotyczą dokładnie jednego kraju i w przypadku których krajem tym
jest Kanada, Francja, Japonia, Wielka Brytania, USA lub RFN. W przypadku
tego problemu mamy do dyspozycji \textbf{13441} próbek, w których (po uproszczonej
stemizacji i usunięciu słów nieznaczących) występuje \textbf{28145} różnych słów.
\item \textbf{Tematy} -- próbki wybierane z tego samego zbioru, co w przypadku
problemu \emph{Kraje}, jednakże tym razem klasami względem których chcemy rozróżniać
próbki są tematy artykułów. Wzięte pod uwagę zostały te próbki, których lista tematów
zawiera temat \emph{interest} albo temat \emph{grain} (próbki dotyczące obu tych
tematów jednocześnie były pomijane). Problem klasyfikacji polega zatem na podziale
zbioru wybranych próbek na dwie klasy, odpowiadające charakterystycznym tematom.
W przypadku tego problemu mamy do dyspozycji \textbf{998} próbek, w których
występuje \textbf{7533} rozróżnialnych, uwzględnianych przez nasz program słów.
\item \textbf{Autorzy} -- tym razem wykorzystaliśmy własny zbiór tekstów, przygotowany
w oparciu o dane przygotowane w ramach inicjatywy \emph{Project Gutenberg}. Z danych
tekstowych z plików \emph{The Complete Works of William Shakespeare} \cite{2} oraz
\emph{The Works of Lord Byron, Vol. 4} \cite{3} usunięte zostały przypisy, a następnie wybrane
zostały ciągłe próbki zawierające po kilka zdań lub wersów, tak aby każda z nich
zawierała od 50 do 200 słów. Kryterium klasyfikacji tak przygotowanych próbek
jest autor tekstu (po usunięciu przypisów, próbki wybierane są wprost z dzieł
literackich, więc autorem każdej z próbek jest William Shakespeare lub Lord George Gordon Byron).
W przypadku tego problemu mamy do dyspozycji \textbf{568} próbek, w których
występuje \textbf{6028} rozróżnialnych, uwzględnianych przez nasz program słów.
\end{enumerate}

\vskip\baselineskip

Dla każdego ze przedstawionych powyżej problemów testowaliśmy różne podejścia do wyboru zbioru
uczącego oraz zbioru sprawdzającego. Domyślnym ustawieniem było potraktowanie $60\%$ początkowych
próbek jako zbioru uczącego, zaś pozostałych $40\%$ próbek -- jako zbioru sprawdzającego.
Oceniane było także zachowanie na mniejszych zbiorach -- wtedy zbiór uczący wybierany był
zawsze od początku, zaś zbiór sprawdzający -- od końca (podanie odpowiedniego argumentu
w przygotowanej przez nas implementacji powoduje, że dozwolone jest nachodzenie na siebie
tych dwóch zbiorów, zatem suma ich miar może przekroczyć liczbę wszystkich próbek w danym
problemie). Dodatkowa opcja pozwala spowodować, aby  przy części testów wybierać próbki
w sposób pseudolosowy (zamiast stosowania schematu opisanego powyżej).


\vskip\baselineskip

Kluczowym elementem testów jest porównanie różnych miar podobieństwa próbek (bądź równoważnie
-- różnych funkcji odległości między próbkami). W zastosowanych przez nas metodach
nacisk położony był albo na ekstrakcję cech (po której można było zastosować metody
porównania oparte na różnych metrykach w $\mathbb{R}^n$) albo na zaawansowane miary podobieństwa.
Możliwości obejmowały:
\begin{itemize}
\renewcommand{\labelitemi}{$\bullet$}
\renewcommand{\labelitemii}{$\circ$}
\item W przypadku zastosowania metod opartych na metrykach w $\mathbb{R}^n$
\begin{itemize}
\item Wybór metody ekstrakcji cech:
\begin{itemize}
\item poprzez obliczanie częstości występowania poszczególnych słów: \emph{,,wszystko''} (patrz sekcja \ref{sec:naiwna}) 
\item poprzez obliczanie częstości występowania wybranych wcześniej słów kluczowych: \emph{,,wybr. sł.''} (patrz sekcja \ref{sec:kluczowe})
\item poprzez wykorzystanie opisanej w poprzednich sekcjach metody wykorzystującej zbiory rozmyte: \emph{,,zb. rozm.''} (patrz sekcja \ref{sec:autorska})
\end{itemize}
\item Wybór odległości na $\mathbb{R}^n$:
\begin{itemize}
\item euklidesowej: \emph{,,\(d_e\)''} (patrz równanie \ref{eq:euklides})
\item ulicznej: \emph{,,\(d_1\)''} (patrz równanie \ref{eq:uliczna}) 
\item Czebyszewa: \emph{,,\(d_\infty\)''} (patrz równanie \ref{eq:czebyszew}) 
\end{itemize}
\end{itemize}
\item W przypadku zastosowania metod opartych na szczególnych miarach podobieństwa próbek
\begin{itemize}
\item miary Jaccarda (patrz równanie \ref{eq:jaccard})
\item metody $n$-gramów (patrz równanie \ref{eq:ngram})
\item miary podobieństwa opartej o słowa kluczowe (patrz sekcja \ref{sec:autorskiepodobienstwo})
\end{itemize}
\end{itemize}

Zdefiniowany zbiór słów kluczowych składa się ze skrótów giełdowych, nazw organizacji,
nazwisk, nazw geograficznych oraz nazw tematów dołączonych do zbioru danych
\emph{Reuters-21578 Text Categorization Collection Data Set}. Po wyróżnieniu
pojedynczych słów oznacza to zastosowanie zbioru \textbf{853} słów kluczowych.

\vskip\baselineskip

Dodatkowym elementem testów była ocena znaczenia parametru \(k\) na wyniki klasyfikacji.
Większość prób wykonywana była przy ustawieniu \(k=5\), lecz dla typowych przypadków
wykonano dodatkowe próby przy \(k=3\) oraz \(k=11\), aby zaobserwować jaki
wpływ będzie to miało na wyniki.

\section{Wyniki}
\footnotetext[1]{przekształcenie na wektor cech w \(R^n\)}
\footnotetext[2]{patrz sekcja \ref{sec:naiwna}}
\footnotetext[3]{patrz równanie \ref{eq:euklides}}
\footnotetext[4]{patrz równanie \ref{eq:uliczna}}
\footnotetext[5]{patrz równanie \ref{eq:czebyszew}}
\footnotetext[6]{patrz sekcja \ref{sec:kluczowe}}
\footnotetext[7]{patrz sekcja \ref{sec:autorska}}
\footnotetext[8]{patrz równanie \ref{eq:jaccard}}
\footnotetext[9]{patrz sekcja \ref{sec:autorskiepodobienstwo}}
\footnotetext[10]{patrz równanie \ref{eq:ngram}}
\include{resultskraje}
%\footnotetext[1]{przekształcenie na wektor cech w \(R^n\)}
%\footnotetext[2]{patrz sekcja \ref{sec:naiwna}}
%\footnotetext[3]{patrz równanie \ref{eq:euklides}}
%\footnotetext[4]{patrz równanie \ref{eq:uliczna}}
%\footnotetext[5]{patrz równanie \ref{eq:czebyszew}}
%\footnotetext[6]{patrz sekcja \ref{sec:kluczowe}}
%\footnotetext[7]{patrz sekcja \ref{sec:autorska}}
%\footnotetext[8]{patrz równanie \ref{eq:jaccard}}
%\footnotetext[9]{patrz sekcja \ref{sec:autorskiepodobienstwo}}
%\footnotetext[10]{patrz równanie \ref{eq:ngram}}
\include{resultstematy}
%\footnotetext[1]{przekształcenie na wektor cech w \(R^n\)}
%\footnotetext[2]{patrz sekcja \ref{sec:naiwna}}
%\footnotetext[3]{patrz równanie \ref{eq:euklides}}
%\footnotetext[4]{patrz równanie \ref{eq:uliczna}}
%\footnotetext[5]{patrz równanie \ref{eq:czebyszew}}
%\footnotetext[6]{patrz sekcja \ref{sec:kluczowe}}
%\footnotetext[7]{patrz sekcja \ref{sec:autorska}}
%\footnotetext[8]{patrz równanie \ref{eq:jaccard}}
%\footnotetext[9]{patrz sekcja \ref{sec:autorskiepodobienstwo}}
%\footnotetext[10]{patrz równanie \ref{eq:ngram}}
\include{resultsautorzy}

Wykonana seria pomiarów, poza zawartymi w tabeli informacjami o skuteczności klasyfikacji
dała nam także pogląd na szybkość poszczególnych metod. Czasy wykonania zależą oczywiście
od parametrów komputera, na którym uruchamiany jest program. W przypadku wybranej przez
nas konfiguracji referencyjnej (znaczenie mają tu tylko proporcje pomiędzy przedstawionymi
czasami) dla zestawu danych \textbf{Kraje} czasy klasyfikacji różnymi metodami prezentują
się następująco:

\begin{table}[H]
\makebox[\textwidth][c]{
\centering
\begin{tabular}[t]{|c|c|c|c|c|}
\hline
& \textbf{$\mathbf{10\%}$ danych} & \textbf{$\mathbf{25\%}$ danych} & \textbf{$\mathbf{50\%}$ danych}  & \textbf{pełny zestaw danych} \\ \hline
\textbf{Zb. rozm.} & $< 1\,\mbox{min}$ & $< 1\,\mbox{min}$ & około $1\,\mbox{min}$ & około $5\,\mbox{min}$ \\ \hline
\textbf{$\mathbf{\mathbb{R}^n}$, wybr. sł.} & $< 1\,\mbox{min}$ & około $5\,\mbox{min}$ & około $15\,\mbox{min}$ & około $1,5\,\mbox{h}$ \\ \hline
\textbf{Jaccard} & około $1\,\mbox{min}$ & około $5\,\mbox{min}$ & około $40\,\mbox{min}$ & \emph{zbyt długo} \\ \hline
\textbf{$\mathbf{\mathbb{R}^n}$, wszystkie} & około $5\,\mbox{min}$ & około $30\,\mbox{min}$ & około $3\,\mbox{h}$ & \emph{zbyt długo} \\ \hline
\textbf{Wg. sł. kluczowych} & około $10\,\mbox{min}$ & około $1,5\,\mbox{h}$ & \emph{zbyt długo} & \emph{zbyt długo} \\ \hline
\textbf{$\mathbf{n}$-gramy} & około $30\,\mbox{min}$ & \emph{zbyt długo} & \emph{zbyt długo} & \emph{zbyt długo} \\ \hline
\end{tabular}
}
\caption{Przybliżone czasy dla wybranego zestawu}
\end{table}

Zapis \emph{zbyt długo} oznacza, że szacowany czas wykonania testu istotnie przekraczał $3\,\mbox{h}$ i wykonywanie
go nie było w naszym odczuciu warunkiem koniecznym aby móc wyciągnąć wnioski z niniejszego zadania laboratoryjnego.

\section{Dyskusja}
Pierwszym wnioskiem, który możemy wysnuć z powyższych wyników jest fakt, że zwiększając parametr \(k\) (w granicach od \(3\) do \(11\)) jakość klasyfikacji rośnie. Widać także,
że wybór metryki ma jedynie niewielki wpływ na jakość klasyfikacji tekstów notatek prasowych. Ma ona natomiast dużo większy wpływ dla klasyfikacji tekstów literackich.
Jeśli chodzi o jakość konkretnych metod klasyfikacji, to najlepsza dla zbioru notatek prasowych (klasyfikacja według kraju i według tematu)
okazała się nasza autorska metoda bazująca na zbiorach rozmytych. Pozwoliła ona w rozsądnym czasie sklasyfikować wszystkie teksty ze skutecznością sięgającą 89\%. Sensownym, aczkolwiek
dużo wolniej działającym wyborem jest też metoda oparta na mierze Jaccarda.
Dla zbioru tekstów znanych pisarzy bardzo dobre wyniki uzyskała metoda naiwnej ekstrakcji z metryką euklidesową,
a także metoda bazująca na mierze Jaccarda. Niektóre metody nie są przydatne, gdyż ich czas obliczeń jest zbyt długi dla dużego zbioru tekstów. Do tych metod należą:
metoda n-gramów, naiwna ekstrakcja bazująca na wszystkich słowach a także podobieństwo bazujące na słowach kluczowych.

Uogólniając powyższe widać, że metoda bazująca na mierze Jaccarda, choć nie jest to metoda najszybsza, to sprawdza się w różnych zastosowaniach. Co więcej metoda ta jest
prosta w implementacji i nie wymaga żadnej wstępnej preparacji danych, na przykład znajdywania słów kluczowych. Jeżeli zależy nam na szybkości, a określony problem pozwala
na zastosowanie metody ekstrakcji opartej o zbiory rozmyte, to warto jej użyć. Jednakże w problemach, w których trudno jest odnaleźć właściwe słowa kluczowe, jak na przykład
w problemie rozpoznawania autorstwa, lepiej użyć metody bardziej ogólnej. Metoda ekstrahująca wszystkie słowa ma dobrą skuteczność, ale jej czas działania  niestety ją dyskwalifikuje.
Zupełnie natomiast nie radzi sobie miara bazująca na n-gramach, ze względu na powolność działania, co wynika z dużej ilości obliczeń niezbędnych do zastosowania metody. 
\section{Wnioski}
\begin{itemize}
\item Nasza autorska metoda bazująca na zbiorach rozmytych jest bardzo skuteczna w problemach w których można wyróżnić słowa kluczowe.
\item Dla problemów, w których wyróżnienie słów kluczowych nie jest skuteczne dobrą metodą jest metoda oparta na mierze Jaccarda.
\item Metoda n-gramów działa zbyt wolno. Wynika to jednak z faktu, że liczymy n-gramy dla liter. Możliwe, że gdybyśmy użyli modyfikacji tej metody, w której zamiast
liter użylibyśmy całych słów, to metoda byłaby szybsza i dawała lepsze wyniki.
\end{itemize}


\begin{thebibliography}{2}
\bibitem{1} Niewiadomski A., 2009, \textit{Materiały, przykłady i ćwiczenia do przedmiotu Komputerowe Systemy Rozpoznawania}, skrypt
\bibitem{2} Shakespeare W., 1564-1616, \textit{The Complete Works of William Shakespeare}, Project Gutenberg, \url{http://www.gutenberg.org/ebooks/100}
\bibitem{3} Lord Byron, G. G. 1788-1824, \textit{The Works of Lord Byron, Vol. 4}, Project Gutenberg, \url{http://www.gutenberg.org/ebooks/20158}
\end{thebibliography}
\end{document}
